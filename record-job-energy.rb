#!/usr/bin/env ruby

require 'fileutils'
require 'open3'
require 'rubygems'
require 'yaml'

#To facilitate the condition in the StandardError, raise this only within the
# cancel job method. This is to prevent attempting to scancel twice.
EnergyRecordError = Class.new(RuntimeError)

POWERCAP_ROOT_DIR = '/sys/devices/virtual/powercap'
DEFAULTS = {out_directory: File.join(__dir__, 'record-job-energy-data'),
            timeout: 600,
           }
HELP_STR = <<-help_str
RECORD-JOB-ENERGY HELP
  This script should be executed as:
      PARALLEL_CMD [PARALLEL_CMD_OPTS] exec.rb [OPTS] PARALLEL_TASK [PARALLEL_TASK_OPTS]
    Where PARALLEL_CMD is srun.
  Options for this script include:
    [-d,--directory]=DIR
      Sets the desired output directory to DIR. Default is:
        #{DEFAULTS[:out_directory]}
    [-t,--timeout]=TIMEOUT
      Sets the maximum time the root process will wait for the other processes to complete
      execution, after the root process has finished its execution. Value is in seconds,
      default value is #{DEFAULTS[:timeout]}.
    --help
      Display this message and exit
help_str
ENERGY_FILE_NAME = 'energy_uj'
MAX_ENERGY_FILE_NAME = 'max_energy_range_uj'
TOTAL_FILE_NAME = "totalled_data"

# Cancel the Slurm job
# Can be passed a job_id and/or a step_id, will try retrieve them if not
# If found will cancel the Slurm job and raise an error
# if not will just raise an error
def cancel_job(message, job_id = nil, step_id = nil, proc_id = nil)
  job_id = get_job_id(error = false) unless job_id
  if job_id and not step_id
    step_id = get_step_id(get_job_directory(job_id), error = false)
  end
  scancel(job_id, step_id) if job_id
  message = if proc_id
              "Record Job Energy error in process #{proc_id} - #{message}"
            else
              "Record Job Energy error - #{message}"
            end
  raise EnergyRecordError, message
end

# Directory creating utility method
def create_directory(directory, proc_id)
  begin
    FileUtils.mkdir_p(directory) unless Dir.exists?(directory)
  rescue SystemCallError
    cancel_job("Error while creating directory #{directory} - aborting",
               proc_id)
  end
end

def execute_task(zones)
  #variables needed for overflow calculation
  zone_paths = zones.map { |z| z[:path] }
  overflow_counts = zone_paths.each_with_object({}) { |zp, h| h[zp] = 0 }
  prev_energies = zone_paths.each_with_object({}) do |zp, h|
    h[zp] = read_energy(zp)
  end
  # Execute task
  Open3.popen2e($task_arr.join(' ')) do |stdin, stdout_and_stderr, wait_thr|
    # Seperate thread to monitor overflow in the powercap files
    thr = Thread.new do
      while true
        # arbitrary value for sleeping between checks
        #   overflow twice within 60 secs unlikely
        sleep 60
        zone_paths.each do |zp|
          new_energy = read_energy(zp)
          if prev_energies[zp] > new_energy
            overflow_counts[zp] += 1
          end
          prev_energies[zp] = new_energy
        end
      end
    end
    # Display output generated by task as it is generated
    while line = stdout_and_stderr.gets do
      puts line
    end
    unless wait_thr.value.success?
      cancel_job("task #{$task_arr.join(' ')} failed", proc_id)
    end
    thr.kill
    # a final check for overflow between previous check & task completion
    zone_paths.each do |zp|
      if prev_energies[zp] > read_energy(zp)
        overflow_counts[zp] += 1
      end
    end
  end
  overflow_counts
end

# Look for an option in the script's options
# Looks for the provided option 'target_opt', return its value if it's in
#   key-value format else returning true if found or nil if not
# Only the first match is considered, prioritising those with values
def find_option(target_opt)
  match_data = nil
  if $opts_arr.find{ |opt| match_data = opt.match(/^--?#{target_opt}=(\S+)$/) }
    return match_data[1]
  elsif $opts_arr.find { |opt| opt =~ /^--?#{target_opt}$/ }
    return true
  else
    return nil
  end
end

# Retrieve the name of a powercap zone from its directory by recursively adding
#   the names of its parents
def find_zone_name(dir)
  cur_dir = dir
  name_arr = []
  while File.dirname(cur_dir) != POWERCAP_ROOT_DIR do
    name_file = File.join(cur_dir, 'name')
    if File.file?(name_file)
      name_arr.unshift(read_first_line(name_file))
    end
    cur_dir = File.dirname(cur_dir)
  end
  name_arr.unshift(File.basename(cur_dir))
end

# Retrieve the specified environment variable
# Optionally, will error if not found
def get_env_var(var, error = true)
  if ENV[var]
    return ENV[var]
  else
    if error
      cancel_job("environment variable '#{var}' not found - aborting")
    else
      return nil
    end
  end
end

# Execute a system-call to retrieve its stdout
def get_from_shell_cmd(cmd, proc_id)
  stdout, stderr, status = Open3.capture3(cmd)
  if not status.success?
    cancel_job("error executing command '#{cmd}' - #{stderr}", proc_id)
  end
  return stdout.strip!
end

# Retrieve the output directory for the job
def get_job_directory(job_id)
  top_directory = find_option(/d|directory/)
  if not top_directory or top_directory == true
    top_directory = DEFAULTS[:out_directory]
  end
  return File.join(top_directory, job_id.to_s)
end

# Retrieve the Slurm job's ID. 2 different keys for backwards compatibility
def get_job_id(error = true)
  job_id = get_env_var('SLURM_JOB_ID', error_ = false)
  job_id = get_env_var('SLURM_JOBID', error_ = error) unless job_id
  job_id.to_i
end


# Retrieve the Slurm step's ID
def get_step_id(job_directory, error = true)
  unless step_id = get_env_var('SLURM_STEP_ID', error = false)
    #NOTE: known issue where, under OpenMPI, the root process of mpiexec will not
    #   receive some environment variables that others will. In this case the
    #   value of the step must be discerned by the directories of previous steps
    if $running_mode and $running_mode == :open_mpi
      if Dir.exist?(job_directory)
        completed_steps = Dir.entries(job_directory).select do |f|
          f.to_i.to_s == f and File.exist?(File.join(job_directory,
                                                     f,
                                                     TOTAL_FILE_NAME))
        end
        step_id = completed_steps.length
      else
        step_id = 0
      end
    else
      step_id = get_env_var('SLURM_STEP_ID', error_ = error)
    end
  end
  step_id.to_i
end

# Take an energy reading for each powercap zone, takes as input the output of
#   get_zone_info. Labels readings with 'tag'
def get_zone_energies(zones, tag)
  zones.each do |zone|
    energy = read_energy(zone[:path])
    zone[tag.to_sym] = {time: Time.now, energy: energy, unit: 'uj'}
  end
  zones
end

# Retrieve a list of hashes containing info on each of the node's powercap zones
def get_zone_info
	zone_dirs = Dir.glob(File.join(POWERCAP_ROOT_DIR, '**', '*energy_uj'))
  zone_dirs.map! do |file|
		File.dirname(file)
	end
	zone_info = []
	zone_dirs.each do |dir|
		info_hash = {}
		info_hash[:path] = dir
		info_hash[:name] = find_zone_name(dir)
		zone_info << info_hash
	end
	zone_info
end

# Read the energy of a single power zone
def read_energy(zone_path)
  read_first_line(File.join(zone_path, ENERGY_FILE_NAME)).to_i
end

# System call to retrieve the first line of a file without loading it into
#   memory
def read_first_line(file)
  `head -n 1 #{file}`.strip
end

# System-call 'scancel', Slurm's job cancelling command
def scancel(job_id, step_id = nil)
  target = job_id.to_s
  target += ".#{step_id.to_s}" if step_id
  Open3.capture2e("scancel #{target}")
end

begin
  if Gem::Version.new(RUBY_VERSION) < Gem::Version.new('2.0.0')
    STDERR.puts "Record Job Energy WARNING - using Ruby version #{RUBY_VERSION}," +
                " recommended is 2.0.0 or later"
  end

  # Split arguments into options for the script and the task to be executed
  $opts_arr, $task_arr = [], []
  iter = (0...ARGV.length).to_enum
  while true
    i = iter.next
    if ARGV[i].start_with?('-') and
        ARGV[i+1] == '=' and not
        ARGV[i+2].start_with?('-')
      $opts_arr << ARGV[i..i+2].join()
      2.times {i = iter.next}
    elsif ARGV[i].start_with?('-')
      $opts_arr << ARGV[i]
    else
      $task_arr = ARGV[i...ARGV.length]
      break
    end
    break if i+1 >= ARGV.length
  end

  if get_env_var('SLURM_PROCID', error = false).nil?
    message = "run this executable only as part of a Slurm job, using srun or mpiexec"
    raise EnergyRecordError, message
  end

  if proc_id = get_env_var('PMI_RANK', error = false)
    $running_mode = :intel_mpi
    num_procs = get_env_var('PMI_SIZE').to_i
    cancel_job("Execution with Intel MPI is not currently supported - please use OpenMPI")
  elsif proc_id = get_env_var('OMPI_COMM_WORLD_RANK', error = false)
    $running_mode = :open_mpi
    num_procs = get_env_var('OMPI_COMM_WORLD_SIZE').to_i
  #NOTE: check presence of a step ID to ensure execution is within srun
  #   not only sbatch
  elsif get_env_var('SLURM_STEP_ID', error = false)
    proc_id = get_env_var('SLURM_PROCID', error = false)
    $running_mode = :srun
    num_procs = get_env_var('SLURM_NTASKS').to_i
  else
    cancel_job("run this executable only as part of a Slurm job, using srun or mpiexec")
  end
  proc_id = proc_id.to_i

  if find_option('help')
    if proc_id == 0
      puts HELP_STR
    end
    exit 0
  end

  job_id = get_job_id
  job_directory = get_job_directory(job_id)
  step_id = get_step_id(job_directory, error = true)
  out_directory = File.join(job_directory, step_id.to_s)

  if $task_arr.empty?
    cancel_job("no task provided - aborting", job_id, step_id, proc_id)
  end

  node = get_from_shell_cmd('hostname', proc_id)
  #NOTE: this value is retrieved from the system as there are Slurm configuration
  #   options that obfuscate the true properties of nodes to Slurm processes.
  #   This obfuscation would confuse the data conclusions.
  num_cores = get_from_shell_cmd('nproc --all', proc_id).to_i
  #NOTE: in Slurm vocab, 'CPUS' usually (& in this case) actually refers to cores
  cpus_per_task = (get_env_var('SLURM_CPUS_PER_TASK', error = false) || 1).to_i

  #Create a file for debugging with info on the current step
  if proc_id == 0
    create_directory(out_directory, proc_id)
    step_info_path = File.join(out_directory, "step_info")
    step_info = { job_id: job_id,
                 step_id: step_id,
                 task: $task_arr.join(' '),
                 parallel_cmd: $running_mode.to_s,
                 num_procs: num_procs,
               }
    yaml_step_info = step_info.to_yaml
    File.open(step_info_path, 'w') { |f| f.write(yaml_step_info) }
  end

  zones = get_zone_info
  get_zone_energies(zones, :starting_energy)
  overflow_counts = execute_task(zones)
  get_zone_energies(zones, :finishing_energy)
  # update the finishing energy to account for any overflow
  zones.each do |z|
    max_range = read_first_line(File.join(z[:path], MAX_ENERGY_FILE_NAME)).to_i
    amt_overflowed = overflow_counts[z[:path]] * max_range
    z[:finishing_energy][:energy] += amt_overflowed
  end

  # Write this process's data to a file
  proc_data = {node: node,
               num_cores: num_cores,
               job_id: job_id,
               step_id: step_id,
               proc_id: proc_id,
               cpus_per_task: cpus_per_task,
               zones: zones}
  out_file_path = File.join(out_directory, proc_id.to_s)
  yaml_proc_data = proc_data.to_yaml
  File.open(out_file_path, 'w') { |f| f.write(yaml_proc_data) }

  if proc_id == 0
    # Wait for other tasks to complete execution. Test this with the number of
    # files in the output directory named for a process ID (i.e. an integer)
    t1 = Time.now
    time_limit = find_option(/t|timeout/)
    time_limit = DEFAULTS[:timeout] if time_limit.nil? or time_limit == true
    while true
      process_files = Dir.entries(out_directory).select do |file|
        file.to_i.to_s == file
      end
      if process_files.length == num_procs
        break
      elsif Time.now - t1 > time_limit.to_i
        message = "timeout waiting for processes to complete"
        cancel_job(message, job_id, step_id, proc_id)
      end
      sleep 1
    end

    # Total the processes data into a single file and output it.
    per_node_data = {total: 0, units: 'Joules'}
    Dir.glob(File.join(out_directory, '*')).each do |file|
      #only process files with a proc id as a name
      next unless File.basename(file).to_i.to_s == File.basename(file)
      proc_data = YAML.load_file(file)
      node_ = proc_data[:node]
      node_proportion = (1.0/proc_data[:num_cores])*proc_data[:cpus_per_task]

      #NOTE Time.at((2**31)-1) gives the maximum possible time value
      #     so all others will be lesser
      per_node_data[node_] ||= {start_time: Time.at(max_time = (2**31)-1),
                                finish_time: Time.at(0)
                               }
      per_node_data[node_][:num_cores] = proc_data[:num_cores]
      per_node_data[node_][:num_procs] ||= 0
      per_node_data[node_][:num_procs] += 1
      per_node_data[node_][:cores_used] ||= 0
      per_node_data[node_][:cores_used] += proc_data[:cpus_per_task]
      per_node_data[node_][:zones] ||= {}

      proc_data[:zones].each do |zone|
        zone_name_ = zone[:name].join('-->')
        starting_energy = zone[:starting_energy][:energy]
        finishing_energy = zone[:finishing_energy][:energy]
        change = finishing_energy - starting_energy
        change = change.to_f / 1000000 if zone[:unit] = 'uj'
        process_change = change*node_proportion
        process_change = process_change.round(7)
        per_node_data[node_][:zones][zone_name_] ||= 0
        per_node_data[node_][:zones][zone_name_] += process_change
        per_node_data[node_][:node_total] ||= 0
        per_node_data[node_][:node_total] += process_change

        if per_node_data[node_][:start_time] > zone[:starting_energy][:time]
          per_node_data[node_][:start_time] = zone[:starting_energy][:time]
        end
        if per_node_data[node_][:finish_time] < zone[:finishing_energy][:time]
          per_node_data[node_][:finish_time] = zone[:finishing_energy][:time]
        end
        per_node_data[:total] += process_change
      end
    end
    per_node_data[:step_info] = step_info
    per_node_data.each do |k, v|
      next unless v.respond_to?(:key?) and v.key?(:node_total)
      elapsed_seconds = v[:finish_time] - v[:start_time]
      v[:elapsed_time] =  Time.at(elapsed_seconds).utc.strftime("%H:%M:%S:%5N")
    end
    yaml_per_node_data = per_node_data.to_yaml
    totals_out_file_path = File.join(out_directory, TOTAL_FILE_NAME)
    File.open(totals_out_file_path, 'w') { |f| f.write(yaml_per_node_data) }
  end
# Rescue any StandardError during execution with a call to cancel the Slurm job.
#   Then re-raise the exception.
rescue => e
  raise e if e.is_a?(EnergyRecordError)
  step_id ||= nil
  scancel(job_id, step_id) if job_id
  raise e
end
